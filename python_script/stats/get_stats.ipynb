{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from exts_used_count import *\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../../datasets/'\n",
    "json_path = '../../json_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary which counts how many times the same column name is used in all datasets\n",
    "columnName2datasets = {}\n",
    "# dictionary which counts how many times x (i.e. a number) columns are in all datasets\n",
    "numColumns2datasets = {}\n",
    "# dictionary which counts how many times x (i.e. a number) rows are in all datasets\n",
    "numRows2datasets = {}\n",
    "# tot rows in all datasets\n",
    "tot_num_row = 0\n",
    "# tot cols in all datasets\n",
    "tot_num_col = 0\n",
    "\n",
    "for file in os.listdir(json_path):\n",
    "    filepath = f\"{json_path}/{file}\"\n",
    "    dataset = pd.read_json(filepath)\n",
    "    # get columns name (case insensitive)\n",
    "    columnsName = dataset.axes[1]\n",
    "    # get number of rows of current dataset\n",
    "    num_row_dataset = len(dataset.axes[0])\n",
    "    # get number of columns of current dataset\n",
    "    num_column_dataset = len(columnsName)\n",
    "    # update total number of rows of all datasets\n",
    "    tot_num_row += num_row_dataset\n",
    "    # update total number of columns of all datasets\n",
    "    tot_num_col += num_column_dataset\n",
    "\n",
    "    # update dictionaries\n",
    "    if num_row_dataset not in numRows2datasets:\n",
    "        numRows2datasets[num_row_dataset] = 1\n",
    "    else:\n",
    "        numRows2datasets[num_row_dataset] += 1\n",
    "\n",
    "    if num_column_dataset not in numColumns2datasets:\n",
    "        numColumns2datasets[num_column_dataset] = 1\n",
    "    else:\n",
    "        numColumns2datasets[num_column_dataset] += 1\n",
    "    \n",
    "    for colName in columnsName:\n",
    "        # Le colonne lette messe in lower case\n",
    "        colName = colName.lower()\n",
    "        # colName = re.sub(\"_\",\" \", colName)\n",
    "        if colName in columnName2datasets:\n",
    "            columnName2datasets[colName] += 1\n",
    "        else:\n",
    "            columnName2datasets[colName] = 1\n",
    "\n",
    "print(\"Tot cols:\", tot_num_col)\n",
    "print(\"Tot rows:\", tot_num_row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# Ordino le mappe per chiavi\n",
    "numColumns2datasetsByKey = collections.OrderedDict(sorted(numColumns2datasets.items()))\n",
    "numRows2datasetsByKey = collections.OrderedDict(sorted(numRows2datasets.items()))\n",
    "columnName2datasetsByKey = collections.OrderedDict(sorted(columnName2datasets.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"columnName2datasets\", columnName2datasetsByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numColumns2datasets\", numColumns2datasetsByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows2datasets\", numRows2datasetsByKey)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered by value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordina le mappe per valore\n",
    "numColumns2datasetsByValue = {numCol: numDb for numCol, numDb in sorted(numColumns2datasets.items(), key=lambda item: item[1], reverse=True)}\n",
    "numRows2datasetsByValue = {numRow: numDb for numRow, numDb in sorted(numRows2datasets.items(), key=lambda item: item[1], reverse=True)}\n",
    "columnName2datasetsByValue = {nameCol: numDb for nameCol, numDb in sorted(columnName2datasets.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"columnName2datasets\", columnName2datasetsByValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({key : [columnName2datasetsByValue[key]] for key in columnName2datasetsByValue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numColumns2datasets\", numColumns2datasetsByValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows2datasets\", numRows2datasetsByValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"File types used\", exts_count(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che calcola la distribuzione di \n",
    "# 'num2count' su 'steps' intervalli\n",
    "def compute_distribution(num2count, steps = 5):\n",
    "    nums = num2count.keys()\n",
    "    \n",
    "    # calcol minimo e massimo valore \n",
    "    # delle chiavi di 'num2count'\n",
    "    minNum = min(nums)\n",
    "    maxNum = max(nums)\n",
    "\n",
    "    # Questo (steps + 1) aggiusta alcuni problemi\n",
    "    # su Lower e Upper bound ~non so il perch√®~\n",
    "    # (ho pensato che 'lb + 1' incrementi lo 'stepSize'\n",
    "    # di '1' ad ogni fine step per un incremento totale\n",
    "    # di 'steps - 1' sui bound)\n",
    "    length = (maxNum - minNum) - steps + 1 \n",
    "    \n",
    "    if length <= 0: return  \n",
    "    \n",
    "    stepSize = length // steps\n",
    "    r = length % steps\n",
    "    \n",
    "    lb = minNum\n",
    "    step2count = {}\n",
    "    for _ in range(steps):\n",
    "        ub = lb + stepSize + int(r > 0)\n",
    "\n",
    "        step2count[(lb, ub)] = 0\n",
    "        for num in nums:\n",
    "            if (lb <= num and num <= ub):\n",
    "                step2count[(lb, ub)] += num2count[num]\n",
    "        lb = ub + 1\n",
    "        r -= 1\n",
    "\n",
    "    return step2count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_distribution(numColumns2datasets, 5)\n",
    "pd.DataFrame({ key: [df[key]] for key in df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_distribution(numRows2datasets, 5)\n",
    "pd.DataFrame({ key: [df[key]] for key in df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informazioni catalogate per anni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "l = list(columnName2datasetsByValue.keys())\n",
    "r = re.compile('.*[0-9].*')\n",
    "ret = list(filter(r.match,l))\n",
    "for i in ret:\n",
    "    if \"revenue\" in i:\n",
    "        print(i)\n",
    "\n",
    "for i in ret:\n",
    "    if \"employees\" in i:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75ba0f077842d729852f72f653d8bd29b9d81a568bccb91dac0b85029caf3bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
