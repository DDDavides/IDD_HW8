{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valentine import valentine_match, valentine_metrics\n",
    "from valentine.algorithms import Coma\n",
    "from valentine.algorithms import Cupid\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import pandas as pd\n",
    "from compute_match import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './csv/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione dizionari che associa il nome del file al file .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset sono in formato json necessariamente\n",
    "path = \"../../json_datasets\"\n",
    "\n",
    "# Dizionario Key=Nome del file, Value=File json associato (letto da filepath)\n",
    "data_frames = {}\n",
    "# Per tutti i file dentro la cartella dei dataset\n",
    "for file in os.listdir(path):\n",
    "    # Prendo il path del file\n",
    "    filepath = f\"{path}/{file}\"\n",
    "    # Update del dizionario\n",
    "    data_frames[file] = (pd.read_json(filepath))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione di tutte le coppie di dataset da valutare (evitando ripetizioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendo tutti i nomi dei file\n",
    "keys = list(data_frames.keys())\n",
    "tuples = []\n",
    "# Il numero di dataframes\n",
    "dfs_len = len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preso un dataframe, lo confronto con tutti i dataframes successivi (così evito di confrontare coppie già confrontate)\n",
    "for i in range(dfs_len):\n",
    "    for j in range(i + 1, dfs_len):\n",
    "        dfl = data_frames[keys[i]]\n",
    "        dfr = data_frames[keys[j]]\n",
    "        # le tuple da passare al metodo di matching = nome dataset1, nome dataset2, dataframe1, dataframe2\n",
    "        tuples.append((keys[i], keys[j], dfl, dfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valentine schema matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_multithread(tuples):\n",
    "    result = []\n",
    "    # Creo un pool per l'esecuzione multi processore (per velocizzare il matching tra tutte le coppie di dataframes)\n",
    "    with Pool() as pool:\n",
    "        # Ogni pool esegue la funzione (primo parametro), passandogli le tuple (secondo parametro)\n",
    "        # result è una lista di tuple ove una tupla è il risultato della funzione mappata\n",
    "        result = pool.map(calculate_match_coma_schema, tuples)\n",
    "    return result\n",
    "\n",
    "def matches_to_table(result):\n",
    "    matches = pd.DataFrame()\n",
    "    # Per ogni risultato ottenuto dal matching\n",
    "    for match in result:\n",
    "    # Prendo il valore ritornato dalla funzione valentine_match \n",
    "    # e.g. match[2] = ((table_1, 'Cited by'),(table_2, 'Cited by')): 0.83\n",
    "        for key in match[2].keys():\n",
    "            # e.g. key = (table_1, 'Cited by'),(table_2, 'Cited by')\n",
    "            d = dict()\n",
    "            d[\"table_1\"] = match[0]\n",
    "            d[\"table_2\"] = match[1]\n",
    "            d[\"column_table_1\"] = key[0][1]\n",
    "            d[\"column_table_2\"] = key[1][1]\n",
    "            d[\"match_value\"] = match[2][key]\n",
    "            # Aggiungiamo al dataframe l'ennupla\n",
    "            matches = pd.concat([matches, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    return matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabella per la visualizzazione dei risultati dello schema matching con Valentine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "# Calcola i match per tutte le coppie di datasets definite in tuples\n",
    "result = calculate_match_multithread(tuples)\n",
    "finish_time = time.perf_counter()\n",
    "\n",
    "# Definizione del nome delle colonne della tabella\n",
    "columns = [\"table_1\", \"table_2\", \"column_table_1\", \"column_table_2\", \"match_value\"]\n",
    "# Creo il dataframe (la tabella in questione)\n",
    "matches = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Porta tutti i match in formato tabellare\n",
    "matches = matches_to_table(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matches).to_csv(csv_path + \"matches.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema mediato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema mediato definito manualmente tramite attributi di interesse e che fanno maggior match\n",
    "mediated_schema_columns = ['name', 'country', 'market cap', 'founded year', 'employees', 'industry', 'sector',\n",
    "     'ceo', 'revenue', 'Stock', 'share price', 'city', 'address', 'website']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediated_schema = pd.DataFrame(columns=mediated_schema_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di tutte le coppie (schema-mediato, dataset)\n",
    "matches_with_mediated = {}\n",
    "for i in range(dfs_len):\n",
    "    dfl = mediated_schema\n",
    "    dfr = data_frames[keys[i]]\n",
    "    # le tuple da passare al metodo di matching = nome dataset1, nome dataset2, dataframe1, dataframe2\n",
    "    tuples.append(('mediated_schema', keys[i], dfl, dfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches con lo schema mediato\n",
    "result = calculate_match_multithread(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches_to_table(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matches).to_csv(csv_path + \"matches_with_mediated.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riempimento schema mediato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(csv_path + 'matches_with_mediated.csv')\n",
    "tables_to_columns = dict()\n",
    "# Per tutte le tabelle in match nella colonna table 2 vado a prendermi\n",
    "# le colonne con match >= 0.5 con una colonna dello schema mediato\n",
    "for table_name in set(matches['table_2']):\n",
    "    # Prende le colonne con table 2 uguale a table name\n",
    "    table = matches.loc[matches['table_2'] == table_name]\n",
    "    columns = set()\n",
    "    for ind in table.index:\n",
    "        if table['match_value'][ind] >= 0.5:\n",
    "            columns.add((table['column_table_1'][ind], table['column_table_2'][ind]))\n",
    "    tables_to_columns[table_name] = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot concat schema final with:  Gren-ft.com.json\n",
      "Cannot concat schema final with:  FR-ft.json\n",
      "Cannot concat schema final with:  DDD-ft.com.json\n",
      "Cannot concat schema final with:  DDD-companiesmarketcap.com.json\n",
      "Cannot concat schema final with:  Silvestri-ft.com.json\n"
     ]
    }
   ],
   "source": [
    "schema_final = pd.DataFrame(columns=mediated_schema_columns).astype(str)\n",
    "\n",
    "# Per tutti i dataset vai a inserire i dati nello schema mediato\n",
    "for df_name in tables_to_columns.keys():\n",
    "    df_aligned = pd.DataFrame()\n",
    "    \n",
    "    # Per tutti i match del dataset effettua una proiezione sulle colonne in match e rinominale per allinearle allo schema mediato\n",
    "    for match in tables_to_columns[df_name]:    \n",
    "        tmp = data_frames[df_name][match[1]].to_frame()\n",
    "        tmp = tmp.rename(columns={match[1]: match[0]})\n",
    "        df_aligned = pd.concat([df_aligned, tmp], axis=1)\n",
    "\n",
    "    try:\n",
    "        schema_final = pd.concat([schema_final, df_aligned], ignore_index=True, sort=False)\n",
    "    except:\n",
    "        print(\"Cannot concat schema final with: \", df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_final = pd.read_csv(csv_path + \"schema_final.csv\", index_col=0)\n",
    "schema_final = schema_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_final.to_csv(csv_path + \"schema_final.csv\", index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sch = schema_final.iloc[:10]\n",
    "# sch.to_csv(csv_path + \"schema_final_10.csv\", index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20fe05bf6d812f8581d0c3885f26a8156e46b0ff73914791c267a01ece645732"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
