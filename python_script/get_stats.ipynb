{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from exts_used_count import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../json_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot cols: 0\n",
      "Tot rows: 0\n",
      "Columns2datasets {}\n",
      "Rows2datasets {}\n",
      "columnName2datasets {}\n",
      "file types used {'.csv': 25, '.jsonl': 4, '.json': 20, '.xlsx': 1, '.xls': 3}\n"
     ]
    }
   ],
   "source": [
    "# dictionary which counts how many times the same column name is used in all datasets\n",
    "columnName2datasets = {}\n",
    "# dictionary which counts how many times x (i.e. a number) columns are in all datasets\n",
    "numColumns2datasets = {}\n",
    "# dictionary which counts how many times x (i.e. a number) rows are in all datasets\n",
    "numRows2datasets = {}\n",
    "# tot rows in all datasets\n",
    "tot_num_row = 0\n",
    "# tot cols in all datasets\n",
    "tot_num_col = 0\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    filepath = f\"{path}/{file}\"\n",
    "    dataset = pd.read_json(filepath)\n",
    "    # get columns name\n",
    "    columnsName = dataset.axes[1]\n",
    "    # get number of rows of current dataset\n",
    "    num_row_dataset = len(dataset.axes[0])\n",
    "    # get number of columns of current dataset\n",
    "    num_column_dataset = len(columnsName)\n",
    "    # update total number of rows of all datasets\n",
    "    tot_num_row += num_row_dataset\n",
    "    # update total number of columns of all datasets\n",
    "    tot_num_col += num_column_dataset\n",
    "\n",
    "    # update dictionaries\n",
    "    if num_row_dataset not in numRows2datasets:\n",
    "        numRows2datasets[num_row_dataset] = 1\n",
    "    else:\n",
    "        numRows2datasets[num_row_dataset] += 1\n",
    "\n",
    "    if num_column_dataset not in numRows2datasets:\n",
    "        numColumns2datasets[num_column_dataset] = 1\n",
    "    else:\n",
    "        numColumns2datasets[num_column_dataset] += 1\n",
    "    \n",
    "    for colName in columnsName:\n",
    "        if colName in columnName2datasets:\n",
    "            columnName2datasets[colName] += 1\n",
    "        else:\n",
    "            columnName2datasets[colName] = 1\n",
    "\n",
    "print(\"Tot cols:\", tot_num_col)\n",
    "print(\"Tot rows:\", tot_num_row)\n",
    "print(\"Columns2datasets\", numColumns2datasets)\n",
    "print(\"Rows2datasets\", numRows2datasets)\n",
    "print(\"columnName2datasets\", columnName2datasets)\n",
    "print(\"file types used\", exts_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20fe05bf6d812f8581d0c3885f26a8156e46b0ff73914791c267a01ece645732"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
